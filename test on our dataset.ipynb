{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "media pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import mediapipe as mp\n",
    "import os\n",
    "from sklearn.metrics import jaccard_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"D:\\\\electrical eng\\\\Research\\\\rppg\\\\khalaj\\\\selfie_multiclass_256x256.tflite\"\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "def preprocess_image(image, input_shape):\n",
    "    input_height, input_width = input_shape[1:3]\n",
    "    image_resized = cv2.resize(image, (input_width, input_height))\n",
    "    image_normalized = image_resized.astype(np.float32) / 255.0\n",
    "    return np.expand_dims(image_normalized, axis=0)\n",
    "\n",
    "def postprocess_output(output, image_shape, threshold=3):\n",
    "    output = output.squeeze()\n",
    "    output_resized = cv2.resize(output, (image_shape[1], image_shape[0]))\n",
    "    mask = output_resized > threshold\n",
    "    return np.stack([mask] * 3, axis=-1)  # Create a 3-channel mask\n",
    "\n",
    "BG_COLOR = (192, 192, 192)  # gray\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "\n",
    "    image = cv2.flip(image, 1)\n",
    "\n",
    "    \n",
    "\n",
    "    input_shape = input_details[0]['shape']\n",
    "    input_image = preprocess_image(image, input_shape)\n",
    "\n",
    "\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_image)\n",
    "\n",
    "    interpreter.invoke()\n",
    "\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "    mask = postprocess_output(output_data, image.shape, threshold=3)\n",
    "\n",
    "    mask1 = mask[:, :,3 ]  # Ensure mask has 3 channels\n",
    "    mask2 = mask[:, :,2 ] \n",
    "    mask = mask1 + mask2\n",
    "\n",
    "    bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
    "    bg_image[:] = BG_COLOR\n",
    "    output_image = np.where(mask, image, bg_image)\n",
    "\n",
    "    cv2.imshow('TFLite Selfie Segmentation', output_image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "work on a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"D:\\\\electrical eng\\\\term 6\\\\dip\\\\Project\\\\datasets\"\n",
    "output_dir = \"D:\\\\electrical eng\\\\term 6\\\\dip\\\\Project\\\\mediapipe-mask\"\n",
    "image_dir = input_dir\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_dataset (1).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_dataset (10).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_dataset (11).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_dataset (12).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_dataset (13).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_dataset (14).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_dataset (15).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_dataset (2).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_dataset (3).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_dataset (4).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_dataset (5).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_dataset (6).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_dataset (7).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_dataset (8).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_dataset (9).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_seg_ash (1).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_seg_ash (2).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_seg_ash (3).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_seg_ash (4).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_seg_ash (5).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_seg_out (1).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_seg_out (2).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_seg_out (3).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_seg_out (4).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_seg_out (5).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_seg_out (6).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_seg_out (7).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_seg_r (1).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_seg_r (2).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_seg_r (3).jpg\n",
      "Processed and saved: D:\\electrical eng\\term 6\\dip\\Project\\mediapipe-mask\\skin_seg_r (4).jpg\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(input_dir):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_path = os.path.join(input_dir, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        if image is None:\n",
    "            print(f\"Failed to read {image_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        input_shape = input_details[0]['shape']\n",
    "        input_image = preprocess_image(image, input_shape)\n",
    "\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_image)\n",
    "        interpreter.invoke()\n",
    "\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        mask = postprocess_output(output_data, image.shape, threshold=3)\n",
    "\n",
    "        mask1 = mask[:, :,3 ]  # Ensure mask has 3 channels\n",
    "        mask2 = mask[:, :,2 ] \n",
    "        mask = mask1 + mask2\n",
    "\n",
    "        bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
    "        bg_image[:] = BG_COLOR\n",
    "        output_image = np.where(mask, image, bg_image)\n",
    "\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        cv2.imwrite(output_path, output_image)\n",
    "        print(f\"Processed and saved: {output_path}\")\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gaussian_blur and histogram_equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_histogram_equalization(image):\n",
    "    img_yuv = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "    img_yuv[:, :, 0] = cv2.equalizeHist(img_yuv[:, :, 0])\n",
    "    return cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "\n",
    "def apply_gaussian_blur(image, kernel_size=(5, 5)):\n",
    "    return cv2.GaussianBlur(image, kernel_size, 0)\n",
    "\n",
    "def calculate_metrics(pred_mask, true_mask):\n",
    "    pred_flat = pred_mask.flatten()\n",
    "    true_flat = true_mask.flatten()\n",
    "\n",
    "    iou = jaccard_score(true_flat, pred_flat, average='binary')\n",
    "    precision = precision_score(true_flat, pred_flat, average='binary')\n",
    "    recall = recall_score(true_flat, pred_flat, average='binary')\n",
    "    f1 = f1_score(true_flat, pred_flat, average='binary')\n",
    "    dice = (2 * precision * recall) / (precision + recall)  # Dice coefficient\n",
    "\n",
    "    return iou, precision, recall, f1, dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_dataset(image_dir, output_mask_dir):\n",
    "    os.makedirs(output_mask_dir, exist_ok=True)\n",
    "\n",
    "    for image_file in os.listdir(image_dir):\n",
    "        if image_file.endswith('.jpg') or image_file.endswith('.png'):\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            mask_filename = os.path.splitext(image_file)[0] + '.png'  # Assuming mask format is .png\n",
    "\n",
    "            image = cv2.imread(image_path)\n",
    "            # Apply histogram equalization\n",
    "            image = apply_histogram_equalization(image)\n",
    "            # Apply Gaussian blur\n",
    "            image = apply_gaussian_blur(image)\n",
    "            \n",
    "            input_shape = input_details[0]['shape']\n",
    "            input_image = preprocess_image(image, input_shape)\n",
    "            \n",
    "            interpreter.set_tensor(input_details[0]['index'], input_image)\n",
    "            interpreter.invoke()\n",
    "            output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "            \n",
    "            pred_mask = postprocess_output(output_data, image[:,:,0].shape, threshold=3)  # Adjust threshold if needed\n",
    "\n",
    "            pred_mask_1 = pred_mask[:,:,2]\n",
    "            pred_mask_2 = pred_mask[:,:,3]\n",
    "            pred_mask = pred_mask_1 + pred_mask_2\n",
    "\n",
    "            bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
    "            bg_image[:] = BG_COLOR\n",
    "            # pred_mask_33 = np.repeat(pred_mask[:, :, np.newaxis], axis=2)   # Expand mask to have 3 channels\n",
    "            output_image = np.where(pred_mask, image, bg_image)\n",
    "\n",
    "            output_path = os.path.join(output_mask_dir, image_file)\n",
    "            cv2.imwrite(output_path, output_image)\n",
    "            # print(f\"Processed and saved: {output_path}\")\n",
    "            \n",
    "\n",
    "\n",
    "output_mask_dir = \"D:\\\\electrical eng\\\\term 6\\\\dip\\\\Project\\\\dataset_enhabced_masks\" \n",
    "evaluate_model_on_dataset(image_dir,  output_mask_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_skin_color_threshold(image):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    lower_skin = np.array([0,30, 90], dtype=np.uint8)\n",
    "    upper_skin = np.array([255, 255, 255], dtype=np.uint8)\n",
    "    skin_color_mask = cv2.inRange(hsv_image, lower_skin, upper_skin)\n",
    "    return skin_color_mask\n",
    "\n",
    "BG_COLOR = (192, 192, 192) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_dataset(image_dir, output_mask_dir):\n",
    "    os.makedirs(output_mask_dir, exist_ok=True)\n",
    "\n",
    "    for image_file in os.listdir(image_dir):\n",
    "        if image_file.endswith('.jpg') or image_file.endswith('.png') or image_file.endswith('.jpeg'):\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            mask_filename = os.path.splitext(image_file)[0] + '.png'  # Assuming mask format is .png\n",
    "        \n",
    "            image = cv2.imread(image_path)\n",
    "            input_shape = input_details[0]['shape']\n",
    "            input_image = preprocess_image(image, input_shape)\n",
    "            \n",
    "            interpreter.set_tensor(input_details[0]['index'], input_image)\n",
    "            interpreter.invoke()\n",
    "            output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "            \n",
    "            pred_mask = postprocess_output(output_data, image[:,:,0].shape)\n",
    "            pred_mask_1 = pred_mask[:,:,2]\n",
    "            pred_mask_2 = pred_mask[:,:,3]\n",
    "            pred_mask = pred_mask_1 + pred_mask_2\n",
    "\n",
    "            # Convert pred_mask to uint8 for bitwise_and operation\n",
    "            pred_mask = (pred_mask * 255).astype(np.uint8)\n",
    "\n",
    "            # Apply HSV skin color thresholding\n",
    "            skin_color_mask = apply_skin_color_threshold(image)\n",
    "            thresholded_pred_mask = cv2.bitwise_and(pred_mask, pred_mask, mask=skin_color_mask)\n",
    "\n",
    "            # Save the thresholded mask\n",
    "            thresholded_output_path = os.path.join(output_mask_dir, mask_filename)\n",
    "            cv2.imwrite(thresholded_output_path, thresholded_pred_mask)\n",
    "\n",
    "    \n",
    "output_mask_dir = \"D:\\\\electrical eng\\\\term 6\\\\dip\\\\Project\\\\dataset_hsv_mediapipe_masks\" \n",
    "evaluate_model_on_dataset(image_dir,  output_mask_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_dataset(image_dir,  output_mask_dir):\n",
    "    os.makedirs(output_mask_dir, exist_ok=True)\n",
    "    iou_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    dice_scores = []\n",
    "\n",
    "    for image_file in os.listdir(image_dir):\n",
    "        if image_file.endswith('.jpg') or image_file.endswith('.png') or image_file.endswith('.jpeg'):\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            mask_filename = os.path.splitext(image_file)[0] + '.png'  # Assuming mask format is .png\n",
    "\n",
    "            \n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            input_shape = input_details[0]['shape']\n",
    "            input_image = preprocess_image(image, input_shape)\n",
    "            \n",
    "            interpreter.set_tensor(input_details[0]['index'], input_image)\n",
    "            interpreter.invoke()\n",
    "            output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "            \n",
    "            pred_mask = postprocess_output(output_data, image[:,:,0].shape, threshold=3)  # Adjust threshold if needed\n",
    "            pred_mask_1 = pred_mask[:,:,2]\n",
    "            pred_mask_2 = pred_mask[:,:,3]\n",
    "            pred_mask = pred_mask_1 + pred_mask_2\n",
    "\n",
    "            pred_mask = (pred_mask).astype(np.uint8)\n",
    "\n",
    "            # Apply HSV skin color thresholding\n",
    "            skin_color_mask = apply_skin_color_threshold(image)\n",
    "            thresholded_pred_mask = cv2.bitwise_and(pred_mask, pred_mask, mask=skin_color_mask)\n",
    "\n",
    "            # Calculate the proportion of the mask that is non-zero before and after thresholding\n",
    "            mask_coverage_before = np.mean(pred_mask)\n",
    "            mask_coverage_after = np.mean(thresholded_pred_mask)\n",
    "\n",
    "            if mask_coverage_after < 0.5 * mask_coverage_before:\n",
    "                final_pred_mask = pred_mask\n",
    "            else:\n",
    "                final_pred_mask = thresholded_pred_mask\n",
    "\n",
    "            # Save the final mask\n",
    "            final_output_path = os.path.join(output_mask_dir, mask_filename)\n",
    "            cv2.imwrite(final_output_path, final_pred_mask * 255)  # Ensure mask is binary (0 or 255)\n",
    "\n",
    "\n",
    "output_mask_dir = \"D:\\\\electrical eng\\\\term 6\\\\dip\\\\Project\\\\dataset_hsv_combined_mediapipe_masks\" \n",
    "evaluate_model_on_dataset(image_dir, output_mask_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ycbcr only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rgb_to_hsv(image):\n",
    "#     return cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "def rgb_to_ycbcr(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "\n",
    "# def create_rgb_mask(image):\n",
    "#     r, g, b = image[:,:,0], image[:,:,1], image[:,:,2]\n",
    "#     mask = (r > 95) & (g > 40) & (b > 20) & (r > g) & (r > b) & (np.abs(r - g) > 15)\n",
    "#     return mask.astype(np.uint8)\n",
    "\n",
    "# def create_hsv_mask(image):\n",
    "#     hsv_image = rgb_to_hsv(image)\n",
    "#     h, s, v = hsv_image[:,:,0], hsv_image[:,:,1], hsv_image[:,:,2]\n",
    "#     mask = (h >= 0.0) & (h <= 50.0) & (s >= 0.23*255) & (s <= 0.68*255)\n",
    "#     return mask.astype(np.uint8)\n",
    "\n",
    "def create_ycbcr_mask(image):\n",
    "    ycbcr_image = rgb_to_ycbcr(image)\n",
    "    y, cb, cr = ycbcr_image[:,:,0], ycbcr_image[:,:,1], ycbcr_image[:,:,2]\n",
    "    mask = (cr > 135) & (cb > 85) & (y > 80) & (cr <= (1.5862*cb)+20) & (cr >= (0.3448*cb)+76.2069) & \\\n",
    "           (cr >= (-4.5652*cb)+234.5652) & (cr <= (-1.15*cb)+301.75) & (cr <= (-2.2857*cb)+432.85)\n",
    "    return mask.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "def evaluate_model_on_dataset(image_dir, output_ycbcr_dir):\n",
    "    os.makedirs(output_ycbcr_dir, exist_ok=True)\n",
    "\n",
    "    for image_file in os.listdir(image_dir):\n",
    "        if image_file.endswith('.jpg') or image_file.endswith('.png') or image_file.endswith('.jpeg'):\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            mask_filename = os.path.splitext(image_file)[0] + '.png'  # Assuming mask format is .png\n",
    "\n",
    "            image = cv2.imread(image_path)\n",
    " \n",
    "            # Create mask\n",
    "            ycbcr_mask = create_ycbcr_mask(image)\n",
    "\n",
    "            # Save mask\n",
    "            cv2.imwrite(os.path.join(output_ycbcr_dir, mask_filename), ycbcr_mask * 255)\n",
    "\n",
    "\n",
    "\n",
    "output_mask_dir_ycbcr = \"D:\\\\electrical eng\\\\term 6\\\\dip\\\\Project\\\\dataset_ycbcr_masks\"\n",
    "evaluate_model_on_dataset(image_dir,output_mask_dir_ycbcr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ycbcr combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, input_shape):\n",
    "    input_height, input_width = input_shape[1:3]\n",
    "    image_resized = cv2.resize(image, (input_width, input_height))\n",
    "    image_normalized = image_resized.astype(np.float32) / 255.0\n",
    "    return np.expand_dims(image_normalized, axis=0)\n",
    "\n",
    "def evaluate_model_on_dataset(image_dir, output_mask_dir):\n",
    "    os.makedirs(output_mask_dir, exist_ok=True)\n",
    "\n",
    "    for image_file in os.listdir(image_dir):\n",
    "        if image_file.endswith('.jpg') or image_file.endswith('.png') or image_file.endswith('.jpeg'):\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            mask_filename = os.path.splitext(image_file)[0] + '.png'  # Assuming mask format is .png\n",
    "\n",
    "            \n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            input_shape = input_details[0]['shape']\n",
    "            input_image = preprocess_image(image, input_shape)\n",
    "            \n",
    "            interpreter.set_tensor(input_details[0]['index'], input_image)\n",
    "            interpreter.invoke()\n",
    "            output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "            \n",
    "            pred_mask = postprocess_output(output_data, image[:,:,0].shape, threshold=3)  # Adjust threshold if needed\n",
    "            pred_mask_1 = pred_mask[:,:,2]\n",
    "            pred_mask_2 = pred_mask[:,:,3]\n",
    "            pred_mask = pred_mask_1 + pred_mask_2\n",
    "\n",
    "            pred_mask = (pred_mask).astype(np.uint8)\n",
    "\n",
    "        \n",
    "            skin_color_mask = apply_skin_color_threshold(image)\n",
    "            thresholded_pred_mask = cv2.bitwise_and(pred_mask, pred_mask, mask=skin_color_mask)\n",
    "\n",
    "            # Calculate the proportion of the mask that is non-zero before and after thresholding\n",
    "            mask_coverage_before = np.mean(pred_mask)\n",
    "            mask_coverage_after = np.mean(thresholded_pred_mask)\n",
    "\n",
    "            if mask_coverage_after < 0.5 * mask_coverage_before:\n",
    "                final_pred_mask = pred_mask\n",
    "            else:\n",
    "                final_pred_mask = thresholded_pred_mask\n",
    "\n",
    "            # Save the final mask\n",
    "            final_output_path = os.path.join(output_mask_dir, mask_filename)\n",
    "            cv2.imwrite(final_output_path, final_pred_mask * 255)  # Ensure mask is binary (0 or 255)\n",
    "\n",
    "\n",
    "output_mask_dir_ycbcr = \"D:\\\\electrical eng\\\\term 6\\\\dip\\\\Project\\\\dataset_ycbcr_combined_masks\"\n",
    "evaluate_model_on_dataset(image_dir,output_mask_dir_ycbcr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
